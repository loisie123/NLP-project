{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "1. LSTM uitbreiden met Kiperwasser (bidirectional,....)\n",
    "2. pretrainend embedding inlezen en toevoegen (staat al iets over in class BiLSTM gecommend)\n",
    "3. runnen.....\n",
    "4. read_data.py -> create_CONLL-U() testen met evaluate ding wat op de git staat\n",
    "5. Edmonds testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deze hoef je alleen maar 1x te runnen om de nieuwe file aan te maken\n",
    "# de nieuwe file heb ik meegestuurd, dus run maar niet ;-)\n",
    "\n",
    "from read_data import *\n",
    "\n",
    "path_in = 'data/en-ud-train.conllu'\n",
    "path_out = 'data/en-ud-train_extract.conllu'\n",
    "\n",
    "create_CONNL_U(path_in, path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  1.7689 -0.0417 -0.1858  ...   0.3524 -0.9768  0.5545\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.2334 -0.4830 -0.4954  ...  -3.3643  1.7264  0.0202\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  0.5141  1.6216  1.8416  ...   0.3524 -0.9768  0.5545\n",
      "... \n",
      "\n",
      "(26 ,.,.) = \n",
      " -0.4117  0.6481 -0.8983  ...   0.0406  0.6088  0.4512\n",
      "\n",
      "(27 ,.,.) = \n",
      " -0.0656  0.8118  0.3715  ...   0.7616 -0.4065  0.6983\n",
      "\n",
      "(28 ,.,.) = \n",
      " -0.4610  0.4872  0.4560  ...  -3.3643  1.7264  0.0202\n",
      "[torch.FloatTensor of size 29x1x125]\n",
      "\n",
      "(Variable containing:\n",
      "( 0 ,.,.) = \n",
      "\n",
      "Columns 0 to 18 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 19 to 37 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 38 to 56 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 57 to 75 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 76 to 94 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 95 to 99 \n",
      "    0   0   0   0   0\n",
      "\n",
      "( 1 ,.,.) = \n",
      "\n",
      "Columns 0 to 18 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 19 to 37 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 38 to 56 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 57 to 75 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 76 to 94 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 95 to 99 \n",
      "    0   0   0   0   0\n",
      "[torch.FloatTensor of size 2x1x100]\n",
      ", Variable containing:\n",
      "( 0 ,.,.) = \n",
      "\n",
      "Columns 0 to 18 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 19 to 37 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 38 to 56 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 57 to 75 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 76 to 94 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 95 to 99 \n",
      "    0   0   0   0   0\n",
      "\n",
      "( 1 ,.,.) = \n",
      "\n",
      "Columns 0 to 18 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 19 to 37 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 38 to 56 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 57 to 75 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 76 to 94 \n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "\n",
      "Columns 95 to 99 \n",
      "    0   0   0   0   0\n",
      "[torch.FloatTensor of size 2x1x100]\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "multi-target not supported at /Users/soumith/miniconda2/conda-bld/pytorch_1503975723910/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-72b00323da47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/en-ud-train_extract.conllu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/NLP1_Project/NLP1/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(path, lr, epochs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# error of output and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# backpropagate the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 482\u001b[0;31m                                self.ignore_index)\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index)\u001b[0m\n\u001b[1;32m    744\u001b[0m                 \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0maveraged\u001b[0m \u001b[0mover\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mignored\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \"\"\"\n\u001b[0;32m--> 746\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, target, *args)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         getattr(ctx._backend, update_output.name)(ctx._backend.library_state, input, target,\n\u001b[0;32m---> 47\u001b[0;31m                                                   output, *ctx.additional_args)\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: multi-target not supported at /Users/soumith/miniconda2/conda-bld/pytorch_1503975723910/work/torch/lib/THNN/generic/ClassNLLCriterion.c:22"
     ]
    }
   ],
   "source": [
    "# dit kan je runnen om het te testen\n",
    "\n",
    "# de error is heel logisch want output is van dim 21 en input is van dim 2 omdat ik van een embedding uitgegaan ben\n",
    "# dus dat moet nog even gefixed worden!\n",
    "\n",
    "from train import *\n",
    "\n",
    "lr = 10^-6\n",
    "epochs = 10\n",
    "path = 'data/en-ud-train_extract.conllu'\n",
    "train(path, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1634  0.0287  0.0163\n",
      "  0.1482 -0.2001  0.3218\n",
      " -0.0355 -0.0601 -0.4876\n",
      "  0.2345 -0.1893  0.0889\n",
      "  0.1757 -0.0789 -0.1833\n",
      " -0.0704 -0.2159 -0.1695\n",
      " -0.1548  0.3207 -0.1263\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.1542  0.1765 -0.0696\n",
      "  0.0088  0.0796  0.2366\n",
      " -0.0100  0.1292 -0.4150\n",
      "  0.1081  0.0506 -0.0289\n",
      "  0.0645  0.1244 -0.1721\n",
      " -0.0668  0.0579 -0.2966\n",
      " -0.2668  0.2563 -0.0848\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.1435  0.2364 -0.1018\n",
      " -0.0968  0.1845  0.0825\n",
      " -0.0119  0.2131 -0.3363\n",
      "  0.0124  0.1619 -0.0887\n",
      " -0.0120  0.2095 -0.1513\n",
      " -0.0728  0.1783 -0.2246\n",
      " -0.2365  0.2830 -0.0885\n",
      "\n",
      "(3 ,.,.) = \n",
      " -0.1426  0.2662 -0.1135\n",
      " -0.1484  0.2318 -0.0110\n",
      " -0.0280  0.2538 -0.2671\n",
      " -0.0496  0.2144 -0.1147\n",
      " -0.0659  0.2465 -0.1383\n",
      " -0.0876  0.2317 -0.1826\n",
      " -0.2196  0.2934 -0.0910\n",
      "\n",
      "(4 ,.,.) = \n",
      " -0.1447  0.2823 -0.1173\n",
      " -0.1698  0.2571 -0.0597\n",
      " -0.0497  0.2754 -0.2156\n",
      " -0.0884  0.2437 -0.1244\n",
      " -0.1002  0.2663 -0.1308\n",
      " -0.1018  0.2600 -0.1586\n",
      " -0.2062  0.2988 -0.0951\n",
      "\n",
      "(5 ,.,.) = \n",
      " -0.1469  0.2916 -0.1184\n",
      " -0.1764  0.2725 -0.0846\n",
      " -0.0712  0.2877 -0.1813\n",
      " -0.1123  0.2622 -0.1269\n",
      " -0.1208  0.2787 -0.1264\n",
      " -0.1133  0.2769 -0.1446\n",
      " -0.1948  0.3020 -0.0995\n",
      "\n",
      "(6 ,.,.) = \n",
      " -0.1483  0.2975 -0.1186\n",
      " -0.1759  0.2830 -0.0979\n",
      " -0.0897  0.2952 -0.1593\n",
      " -0.1266  0.2751 -0.1265\n",
      " -0.1328  0.2874 -0.1239\n",
      " -0.1219  0.2877 -0.1363\n",
      " -0.1849  0.3042 -0.1036\n",
      "\n",
      "(7 ,.,.) = \n",
      " -0.1488  0.3015 -0.1186\n",
      " -0.1722  0.2905 -0.1055\n",
      " -0.1044  0.3000 -0.1455\n",
      " -0.1350  0.2845 -0.1253\n",
      " -0.1393  0.2937 -0.1224\n",
      " -0.1281  0.2950 -0.1311\n",
      " -0.1765  0.3059 -0.1071\n",
      "\n",
      "(8 ,.,.) = \n",
      " -0.1487  0.3043 -0.1188\n",
      " -0.1675  0.2960 -0.1101\n",
      " -0.1155  0.3033 -0.1368\n",
      " -0.1398  0.2916 -0.1240\n",
      " -0.1427  0.2984 -0.1215\n",
      " -0.1324  0.3000 -0.1277\n",
      " -0.1694  0.3073 -0.1101\n",
      "\n",
      "(9 ,.,.) = \n",
      " -0.1481  0.3063 -0.1189\n",
      " -0.1628  0.3002 -0.1130\n",
      " -0.1235  0.3057 -0.1312\n",
      " -0.1423  0.2969 -0.1230\n",
      " -0.1443  0.3019 -0.1209\n",
      " -0.1354  0.3035 -0.1256\n",
      " -0.1635  0.3083 -0.1125\n",
      "\n",
      "(10,.,.) = \n",
      " -0.1475  0.3079 -0.1191\n",
      " -0.1587  0.3034 -0.1150\n",
      " -0.1293  0.3074 -0.1276\n",
      " -0.1436  0.3009 -0.1222\n",
      " -0.1450  0.3046 -0.1205\n",
      " -0.1375  0.3060 -0.1241\n",
      " -0.1588  0.3092 -0.1143\n",
      "[torch.FloatTensor of size 11x7x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zo werkt lstm\n",
    "\n",
    "embedding_dim = 2\n",
    "hidden_dim = 3\n",
    "num_of_hidden = 5\n",
    "batch_size = 7 # hoeveel data punten in 1 keer\n",
    "seq_len = 11 # ik denk het aantal woorden in een zin\n",
    "\n",
    "lstm = nn.LSTM(embedding_dim,hidden_dim,num_of_hidden)\n",
    "inp = Variable(torch.randn(seq_len, batch_size, embedding_dim))\n",
    "h0 = Variable(torch.randn(num_of_hidden, batch_size, hidden_dim))\n",
    "c0 = Variable(torch.randn(num_of_hidden, batch_size, hidden_dim))\n",
    "output, hn = lstm(inp, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scored by MLP\n",
    "# MLP(x)=W_2 * tanh(W_1 @ x + b_1)+b_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
